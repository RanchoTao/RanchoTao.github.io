---
---

@string{aps = {American Physical Society,}}

@article{yin2021characterizing,
  abbr={ArXiv},
  title={Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings}, 
  author={Yin, Ming and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2105.06029 (Short version at ICML 2021 RL Theory Workshop),},
  year={2021},
  arxiv={2105.06029},
  selected={true}
}

@article{yin2021near,
  abbr={ArXiv},
  title={Near-Optimal Offline Reinforcement Learning via Double Variance Reduction},
  author={Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2102.01748 (Short version at ICML 2021 RL Theory Workshop),},
  arxiv={2102.01748},
  year={2021},
  selected={true}
}




@article{yin2020near,
  abbr={AISTATS},
  award={Oral Presentation},
  html={http://proceedings.mlr.press/v130/yin21a.html},
  arxiv={2007.03760},
  title={Near-optimal Provable Uniform Convergence in Offline Policy Evaluation for Reinforcement Learning},
  author={Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
  journal={International Conference on Artificial Intelligence and Statistics (Short version at Neurips 2020 Offline RL Workshop),},
  year={2021},
  selected={true}
}

@article{yin2020asymptotically,
  abbr={AISTATS},
  title={Asymptotically Efficient Off-policy Evaluation for Tabular Reinforcement Learning},
  author={Yin, Ming and Wang, Yu-Xiang},
  journal={International Conference on Artificial Intelligence and Statistics,},
  volume={17},
  pages={549--560},
  html={http://proceedings.mlr.press/v108/yin20b.html},
  year={2020}
}
